{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JufPZVIGyQ-r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://discuss.pytorch.org/t/how-to-share-weights-between-two-layers/55541/2\n",
        "\n",
        "\n",
        "def init_weights():\n",
        "    pass\n",
        "\n",
        "\n",
        "class ImageAutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, tie_weights=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc3 = nn.Linear(25600, 100, bias=True)\n",
        "\n",
        "        # decoder\n",
        "        self.fc4 = nn.Linear(100, 25600, bias=True)\n",
        "        self.conv5 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv6 = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # utils\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # share encoder decoder weight matrices\n",
        "        if tie_weights:\n",
        "            self._tie_weights()\n",
        "\n",
        "    def _tie_weights(self):\n",
        "        self.fc4.weight.data = self.fc3.weight.data.transpose(0,1)\n",
        "        self.conv5.weight.data = self.conv2.weight.data.transpose(0,1)\n",
        "        self.conv6.weight.data = self.conv1.weight.data.transpose(0,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        h = self.relu(self.conv1(x))\n",
        "        h = self.relu(self.conv2(h))\n",
        "        h = self.pool(h)\n",
        "        h = self.fc3(h.reshape(-1, 25600))\n",
        "        print(h.shape)\n",
        "\n",
        "        # decoder\n",
        "        h = self.fc4(h).T\n",
        "        h = h.reshape(-1, 64, 20, 20)\n",
        "        h = self.upsample(h)\n",
        "        h = self.conv5(h)\n",
        "        x_hat = self.conv6(h)\n",
        "        return x_hat\n",
        "\n",
        "\n",
        "class TextAutoEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, tie_weights=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder\n",
        "        self.fc1 = nn.Linear(32, 400, bias=True)\n",
        "        self.fc2 = nn.Linear(400, 100, bias=True)\n",
        "\n",
        "        # decoder\n",
        "        self.fc3 = nn.Linear(100, 400, bias=True)\n",
        "        self.fc4 = nn.Linear(400, 32, bias=True)\n",
        "\n",
        "        # utils\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        # share encoder decoder weight matrices\n",
        "        if tie_weights:\n",
        "            self._tie_weights()\n",
        "\n",
        "    def _tie_weights(self):\n",
        "        self.fc3.weight.data = self.fc2.weight.data.transpose(0,1)\n",
        "        self.fc4.weight.data = self.fc1.weight.data.transpose(0,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        h = self.relu(self.fc1(x))\n",
        "        h = self.fc2(h)\n",
        "        print(h.shape)\n",
        "\n",
        "        # decoder\n",
        "        h = self.relu(self.fc3(h))\n",
        "        x_hat = self.fc4(h)\n",
        "        return x_hat\n",
        "\n",
        "model = TextAutoEncoder()\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(1, 32)\n",
        "print(x.shape)\n",
        "model(x).shape"
      ],
      "metadata": {
        "id": "5Q8F68pA17Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a59247-3223-46b2-f1d1-ba8a71a5c6dd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "106532\n",
            "TextAutoEncoder(\n",
            "  (fc1): Linear(in_features=32, out_features=400, bias=True)\n",
            "  (fc2): Linear(in_features=400, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=400, bias=True)\n",
            "  (fc4): Linear(in_features=400, out_features=32, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n",
            "torch.Size([1, 32])\n",
            "torch.Size([1, 100])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ImageAutoEncoder()\n",
        "print(sum(p.numel() for p in model.parameters()))\n",
        "print(model)\n",
        "\n",
        "x = torch.randn(1, 3, 40, 40)\n",
        "print(x.shape)\n",
        "model(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iIxhlzTQVby",
        "outputId": "5e9e092e-5086-477f-e690-440cafc80131"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5223079\n",
            "ImageAutoEncoder(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc3): Linear(in_features=25600, out_features=100, bias=True)\n",
            "  (fc4): Linear(in_features=100, out_features=25600, bias=True)\n",
            "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
            "  (relu): ReLU()\n",
            ")\n",
            "torch.Size([1, 3, 40, 40])\n",
            "torch.Size([1, 100])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 40, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}